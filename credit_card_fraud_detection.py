# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1491_T47bjZf4oND2zNqpdDNn4J_YqK-Z
"""

#Loading Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import gridspec
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv("/content/creditcard.csv")
df

#Summary statistics
df.describe()

##We separate the dataset into two groups
fraud = df[df['Class'] == 1] #fraudulent transactions (Class == 1)
valid = df[df['Class'] == 0] #valid transactions (Class == 0)
outlierFraction = len(fraud)/float(len(valid))
print(outlierFraction)
print('Fraud Cases: {}'.format(len(df[df['Class'] == 1])))
print('Valid Transactions: {}'.format(len(df[df['Class'] == 0])))

print("Amount details of the fraudulent transaction")
fraud.Amount.describe()

df = df.dropna(subset=["Class"])

# Now split again
x = df.drop("Class", axis=1)
y = df["Class"]

print("details of valid transaction")
valid.Amount.describe()

#Plotting Correlation Matrix
corrmat = df.corr()
fig = plt.figure(figsize = (12, 9))
sns.heatmap(corrmat, vmax = .8, square = True)
plt.show()

X = df.drop(['Class'], axis = 1) #removes the target column (Class)
Y = df["Class"]
print(X.shape)
print(Y.shape)

xData = X.values
yData = Y.values

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)

rfc = RandomForestClassifier()
rfc.fit(x_train, y_train) #trains the RandomForestClassifier model on the 20% of training data

ypred = rfc.predict(x_test) #Uses the trained model to predict the target labels for the test data

#Evaluating the model for its performance using various metrics such as accuracy, precision, recall, F1-score and the Matthews correlation coefficient.
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix
accuracy = accuracy_score(y_test, ypred)
precision = precision_score(y_test, ypred)
recall = recall_score(y_test, ypred)
f1 = f1_score(y_test, ypred)
mcc = matthews_corrcoef(y_test, ypred)

print("Model Evaluation Metrics:")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print(f"Matthews Correlation Coefficient: {mcc:.4f}")

conf_matrix = confusion_matrix(y_test, ypred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=['Normal', 'Fraud'], yticklabels=['Normal', 'Fraud'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted Class")
plt.ylabel("True Class")
plt.show()